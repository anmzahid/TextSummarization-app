{"ast":null,"code":"var _jsxFileName = \"E:\\\\3-2  semester\\\\ML\\\\ML project 3-2\\\\dialogue-summarizer\\\\src\\\\Models.js\";\nimport React from 'react';\nimport './Models.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction Models() {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"models-page\",\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Models\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 7,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"model-card\",\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"Pegasus Model\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 10,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Model Summary\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 11,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Pegasus is a state-of-the-art abstractive summarization model developed by Google Research. The model is pretrained on a large corpus of news articles and fine-tuned on downstream summarization tasks. Pegasus stands for \\\"Pre-training with Extracted Gap-sentences for Abstractive Summarization.\\\" It uses a novel pretraining objective that involves masking entire sentences rather than individual tokens.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 12,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Training Data\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 14,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Pegasus was pretrained on the C4 dataset (Colossal Clean Crawled Corpus) and fine-tuned on various summarization datasets such as CNN/DailyMail, XSum, and others.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 15,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Languages\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 17,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"English\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 18,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Model Performance\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 20,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Pegasus achieves state-of-the-art results on several benchmark summarization datasets, including CNN/DailyMail and XSum. It generates high-quality, fluent, and coherent summaries.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 21,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Use Cases\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 23,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Pegasus is used for abstractive text summarization tasks, including news summarization, document summarization, and more. It can be applied in various domains where concise text generation is required.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 24,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 9,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"model-card\",\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"BART Model\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 28,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Model Summary\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 29,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"BART is a transformer-based model developed by Facebook AI. It combines bidirectional and autoregressive transformers to achieve strong performance on text generation tasks. BART is pretrained using a denoising autoencoder approach and fine-tuned on downstream tasks such as summarization, translation, and text generation.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 30,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Training Data\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 32,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"BART was pretrained on a large corpus of text from the internet and fine-tuned on specific datasets like CNN/DailyMail for summarization tasks.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 33,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Languages\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 35,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"English\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 36,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Model Performance\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 38,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"BART achieves state-of-the-art results on various natural language processing tasks, including summarization, machine translation, and more. It generates high-quality, fluent, and contextually accurate text.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 39,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"model-heading\",\n        children: \"Use Cases\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 41,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"BART is used for a wide range of natural language generation tasks, including abstractive summarization, dialogue generation, and text completion. It is versatile and effective in generating coherent and contextually relevant text.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 42,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 27,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 6,\n    columnNumber: 9\n  }, this);\n}\n_c = Models;\nexport default Models;\nvar _c;\n$RefreshReg$(_c, \"Models\");","map":{"version":3,"names":["React","jsxDEV","_jsxDEV","Models","className","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["E:/3-2  semester/ML/ML project 3-2/dialogue-summarizer/src/Models.js"],"sourcesContent":["import React from 'react';\r\nimport './Models.css';\r\n\r\nfunction Models() {\r\n    return (\r\n        <div className=\"models-page\">\r\n            <h1>Models</h1>\r\n\r\n            <div className=\"model-card\">\r\n                <h2>Pegasus Model</h2>\r\n                <p className=\"model-heading\">Model Summary</p>\r\n                <p>Pegasus is a state-of-the-art abstractive summarization model developed by Google Research. The model is pretrained on a large corpus of news articles and fine-tuned on downstream summarization tasks. Pegasus stands for \"Pre-training with Extracted Gap-sentences for Abstractive Summarization.\" It uses a novel pretraining objective that involves masking entire sentences rather than individual tokens.</p>\r\n\r\n                <p className=\"model-heading\">Training Data</p>\r\n                <p>Pegasus was pretrained on the C4 dataset (Colossal Clean Crawled Corpus) and fine-tuned on various summarization datasets such as CNN/DailyMail, XSum, and others.</p>\r\n\r\n                <p className=\"model-heading\">Languages</p>\r\n                <p>English</p>\r\n\r\n                <p className=\"model-heading\">Model Performance</p>\r\n                <p>Pegasus achieves state-of-the-art results on several benchmark summarization datasets, including CNN/DailyMail and XSum. It generates high-quality, fluent, and coherent summaries.</p>\r\n\r\n                <p className=\"model-heading\">Use Cases</p>\r\n                <p>Pegasus is used for abstractive text summarization tasks, including news summarization, document summarization, and more. It can be applied in various domains where concise text generation is required.</p>\r\n            </div>\r\n\r\n            <div className=\"model-card\">\r\n                <h2>BART Model</h2>\r\n                <p className=\"model-heading\">Model Summary</p>\r\n                <p>BART is a transformer-based model developed by Facebook AI. It combines bidirectional and autoregressive transformers to achieve strong performance on text generation tasks. BART is pretrained using a denoising autoencoder approach and fine-tuned on downstream tasks such as summarization, translation, and text generation.</p>\r\n\r\n                <p className=\"model-heading\">Training Data</p>\r\n                <p>BART was pretrained on a large corpus of text from the internet and fine-tuned on specific datasets like CNN/DailyMail for summarization tasks.</p>\r\n\r\n                <p className=\"model-heading\">Languages</p>\r\n                <p>English</p>\r\n\r\n                <p className=\"model-heading\">Model Performance</p>\r\n                <p>BART achieves state-of-the-art results on various natural language processing tasks, including summarization, machine translation, and more. It generates high-quality, fluent, and contextually accurate text.</p>\r\n\r\n                <p className=\"model-heading\">Use Cases</p>\r\n                <p>BART is used for a wide range of natural language generation tasks, including abstractive summarization, dialogue generation, and text completion. It is versatile and effective in generating coherent and contextually relevant text.</p>\r\n            </div>\r\n        </div>\r\n    );\r\n}\r\n\r\nexport default Models;\r\n"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAO,cAAc;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEtB,SAASC,MAAMA,CAAA,EAAG;EACd,oBACID,OAAA;IAAKE,SAAS,EAAC,aAAa;IAAAC,QAAA,gBACxBH,OAAA;MAAAG,QAAA,EAAI;IAAM;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAEfP,OAAA;MAAKE,SAAS,EAAC,YAAY;MAAAC,QAAA,gBACvBH,OAAA;QAAAG,QAAA,EAAI;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACtBP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC9CP,OAAA;QAAAG,QAAA,EAAG;MAAkZ;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAEzZP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC9CP,OAAA;QAAAG,QAAA,EAAG;MAAkK;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAEzKP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAS;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC1CP,OAAA;QAAAG,QAAA,EAAG;MAAO;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAEdP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAiB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAClDP,OAAA;QAAAG,QAAA,EAAG;MAAmL;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAE1LP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAS;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC1CP,OAAA;QAAAG,QAAA,EAAG;MAAyM;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC/M,CAAC,eAENP,OAAA;MAAKE,SAAS,EAAC,YAAY;MAAAC,QAAA,gBACvBH,OAAA;QAAAG,QAAA,EAAI;MAAU;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACnBP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC9CP,OAAA;QAAAG,QAAA,EAAG;MAAmU;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAE1UP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC9CP,OAAA;QAAAG,QAAA,EAAG;MAA+I;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAEtJP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAS;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC1CP,OAAA;QAAAG,QAAA,EAAG;MAAO;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAEdP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAiB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAClDP,OAAA;QAAAG,QAAA,EAAG;MAA+M;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAEtNP,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,EAAC;MAAS;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC1CP,OAAA;QAAAG,QAAA,EAAG;MAAuO;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7O,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACL,CAAC;AAEd;AAACC,EAAA,GA1CQP,MAAM;AA4Cf,eAAeA,MAAM;AAAC,IAAAO,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}